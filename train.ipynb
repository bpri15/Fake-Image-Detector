{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.patch_generator import smash_n_reconstruct\n",
    "import preprocessing.filters as f\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_tanh(x):\n",
    "    return tf.clip_by_value(x,-1,1)\n",
    "\n",
    "trainable_model = keras.Sequential([\n",
    "        layers.Input(shape=(256,256,1)),\n",
    "        layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Lambda(hard_tanh)\n",
    "    ])\n",
    "\n",
    "trainable_model.compile(optimizer='adam',loss=keras.losses.BinaryCrossentropy,metrics=['accuracy'])\n",
    "trainable_model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = keras.Sequential([\n",
    "        layers.Input(shape=(254,254,32)),\n",
    "        layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.AveragePooling2D(),\n",
    "        layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.AveragePooling2D(),\n",
    "        layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.AveragePooling2D(),\n",
    "        layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1,activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "classifier.compile(\n",
    "                    optimizer='adam',\n",
    "                    loss='BinaryCrossentropy',\n",
    "                    metrics='binary_accuracy'\n",
    "                )\n",
    "\n",
    "classifier.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(path,label:int):\n",
    "    print(f'üñºÔ∏èimage path: - {path}')\n",
    "    rt,pt = smash_n_reconstruct(path.numpy().decode('utf-8'))\n",
    "    frt = tf.constant([f.apply_all_filters(rt)])\n",
    "    fpt = tf.constant([f.apply_all_filters(pt)])\n",
    "    return (trainable_model.predict(frt)-trainable_model.predict(fpt))[0],label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_map(X,y):\n",
    "    return {\n",
    "        'X':X,\n",
    "        'y':y\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ai = './test_imgs/dataset/fakeV2/fake-v2'\n",
    "ai_imgs = [os.path.join(path_ai,img) for img in os.listdir(path_ai)]\n",
    "ai_label = [1 for i in range(len(ai_imgs))]\n",
    "path_real = './test_imgs/dataset/real'\n",
    "real_imgs = [os.path.join(path_real,img) for img in os.listdir(path_real)]\n",
    "real_label = [0 for i in range(len(real_imgs))]\n",
    "print(len(real_imgs),len(ai_imgs))\n",
    "X_train = ai_imgs[:-21] + real_imgs[:-21]\n",
    "y_train = ai_label[:-21] + real_label[:-21]\n",
    "X_validate = ai_imgs[-21:] + real_imgs[-21:]\n",
    "y_validate = ai_label[-21:] + real_label[-21:]\n",
    "len(X_train),len(y_train),len(X_validate),len(y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = (tf.data.Dataset.from_tensor_slices((X_train,y_train))\n",
    "           .shuffle(len(X_train))\n",
    "           .map(\n",
    "                lambda filepath,label: \n",
    "                tf.py_function(preprocess, [filepath, label],[tf.float64, tf.int32])\n",
    "            )\n",
    "            .batch(batch_size)\n",
    "            .prefetch(tf.data.AUTOTUNE)\n",
    "        )\n",
    "\n",
    "validation_set = (tf.data.Dataset.from_tensor_slices((X_validate,y_validate))\n",
    "           .map(\n",
    "                lambda filepath,label: \n",
    "                tf.py_function(preprocess, [filepath, label],[tf.float64, tf.int32])\n",
    "            )\n",
    "            .batch(10)\n",
    "            .prefetch(tf.data.AUTOTUNE)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/model_checkpoint.h5\"\n",
    "checkpoint_callback = ModelCheckpoint(filepath=checkpoint_path, \n",
    "                                      monitor='val_loss', \n",
    "                                      save_best_only=True,\n",
    "                                      save_weights_only=True,\n",
    "                                      verbose=1)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', \n",
    "                                        patience=5,\n",
    "                                        verbose=1, \n",
    "                                        restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('./classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataset:\n",
    "    train_data = data[0]\n",
    "    train_labels = data[1]\n",
    "    gc.collect()\n",
    "    model.fit(x=train_data,y=train_labels,epochs=5, validation_data=(validation_set), callbacks=[checkpoint_callback, early_stopping_callback])\n",
    "    gc.collect()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing.patch_generator as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './test_imgs/dataset/real\\\\z6ewevdaap5a1.png'\n",
    "path[-4:]\n",
    "# img = Image.open(path)\n",
    "# img = img.resize((256,256))\n",
    "# img = img.convert('RGB')\n",
    "# np.array(img).shape\n",
    "# img.size\n",
    "# a1,a2 = p.img_to_patches(path)\n",
    "# vv = [p.get_pixel_var_degree_for_patch(patch) for patch in a1]\n",
    "# b1,b2 = p.extract_rich_and_poor_textures(vv,a2)\n",
    "# c1 = p.get_complete_image(b1).shape\n",
    "# c2 = p.get_complete_image(b2).shape\n",
    "# c1,c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier.fit(dataset,epochs=5,validation_data=validation_set,callbacks=[checkpoint_callback, early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier.save('./classifier.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
